{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e12db7",
   "metadata": {},
   "source": [
    "### 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1f69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77a903",
   "metadata": {},
   "source": [
    "__2. Animal Character Mapping__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cede735",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_img_map = {\n",
    "    0: \"airplane\", 1: \"automobile\", 2: \"bird\", 3: \"cat\", 4: \"deer\", 5: \"dog\", 6: \"frog\", 7: \"horse\", 8: \"ship\", 9: \"truck\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081910d",
   "metadata": {},
   "source": [
    "__3. Image Preprocessing Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e69f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(f\"Warning: Unable to read image at {image_path}\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (32,32))  # Resize to a fixed size\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58df91",
   "metadata": {},
   "source": [
    "__4. Dataset Loading Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7ccbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_path):\n",
    "    images = []   # empty list\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(dataset_path))\n",
    "    valid_extensions = ('.bmp', '.png', '.jpg', '.jpeg')  # Add other valid extensions if needed\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        for image_name in os.listdir(class_path):\n",
    "            if image_name.lower().endswith(valid_extensions):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                image = load_and_preprocess_image(image_path)\n",
    "                if image is not None:\n",
    "                    images.append(image)\n",
    "                    labels.append(label)\n",
    "    return np.array(images, dtype=np.float32), np.array(labels, dtype=np.int32), class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54807635",
   "metadata": {},
   "source": [
    "__5. Dataset Path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ddaefc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = './dataset/train'\n",
    "test_dataset_path = './dataset/test'\n",
    "\n",
    "train_images, train_labels, train_class_names = load_dataset(train_dataset_path)\n",
    "test_images, test_labels, test_class_names = load_dataset(test_dataset_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045aaaaa",
   "metadata": {},
   "source": [
    "__6__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a28ca53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Convolution Block 1\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolution Block 2\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Convolution Block 3\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Flatten and Dense Layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d927c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_images1, X_vali, train_labels1, y_vali = train_test_split(train_images, train_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7bc96",
   "metadata": {},
   "source": [
    "__7. Build Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7879041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">356,234</span> (1.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m356,234\u001b[0m (1.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">356,234</span> (1.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m356,234\u001b[0m (1.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = (32, 32, 1)  # Height, Width, Channels\n",
    "num_classes = len(train_class_names)  # Number of unique Bengali letters\n",
    "\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f8f11",
   "metadata": {},
   "source": [
    "__8. Compile the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b194262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.3950 - loss: 1.6771 - val_accuracy: 0.5396 - val_loss: 1.3310\n",
      "Epoch 2/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.5526 - loss: 1.2747 - val_accuracy: 0.6450 - val_loss: 1.0416\n",
      "Epoch 3/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.6149 - loss: 1.1110 - val_accuracy: 0.6954 - val_loss: 0.8822\n",
      "Epoch 4/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.6514 - loss: 1.0103 - val_accuracy: 0.7072 - val_loss: 0.8587\n",
      "Epoch 5/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.6764 - loss: 0.9309 - val_accuracy: 0.7444 - val_loss: 0.7382\n",
      "Epoch 6/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.6980 - loss: 0.8702 - val_accuracy: 0.7608 - val_loss: 0.6799\n",
      "Epoch 7/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7167 - loss: 0.8178 - val_accuracy: 0.7854 - val_loss: 0.6108\n",
      "Epoch 8/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7347 - loss: 0.7715 - val_accuracy: 0.8004 - val_loss: 0.5643\n",
      "Epoch 9/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7483 - loss: 0.7241 - val_accuracy: 0.8266 - val_loss: 0.5073\n",
      "Epoch 10/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7613 - loss: 0.6845 - val_accuracy: 0.8314 - val_loss: 0.5029\n",
      "Epoch 11/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7713 - loss: 0.6490 - val_accuracy: 0.8448 - val_loss: 0.4589\n",
      "Epoch 12/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7774 - loss: 0.6293 - val_accuracy: 0.8560 - val_loss: 0.4255\n",
      "Epoch 13/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.7886 - loss: 0.5991 - val_accuracy: 0.8724 - val_loss: 0.3915\n",
      "Epoch 14/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.7964 - loss: 0.5719 - val_accuracy: 0.8570 - val_loss: 0.4044\n",
      "Epoch 15/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8038 - loss: 0.5499 - val_accuracy: 0.8806 - val_loss: 0.3548\n",
      "Epoch 16/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8125 - loss: 0.5275 - val_accuracy: 0.8888 - val_loss: 0.3329\n",
      "Epoch 17/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8190 - loss: 0.5056 - val_accuracy: 0.8964 - val_loss: 0.3061\n",
      "Epoch 18/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8226 - loss: 0.4936 - val_accuracy: 0.9106 - val_loss: 0.2723\n",
      "Epoch 19/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8288 - loss: 0.4753 - val_accuracy: 0.9142 - val_loss: 0.2580\n",
      "Epoch 20/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8339 - loss: 0.4599 - val_accuracy: 0.9182 - val_loss: 0.2498\n",
      "Epoch 21/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8397 - loss: 0.4448 - val_accuracy: 0.8876 - val_loss: 0.3156\n",
      "Epoch 22/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8467 - loss: 0.4247 - val_accuracy: 0.9172 - val_loss: 0.2475\n",
      "Epoch 23/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8503 - loss: 0.4165 - val_accuracy: 0.9210 - val_loss: 0.2273\n",
      "Epoch 24/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8542 - loss: 0.4028 - val_accuracy: 0.9364 - val_loss: 0.1966\n",
      "Epoch 25/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8557 - loss: 0.3934 - val_accuracy: 0.9442 - val_loss: 0.1728\n",
      "Epoch 26/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8592 - loss: 0.3832 - val_accuracy: 0.9428 - val_loss: 0.1837\n",
      "Epoch 27/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8636 - loss: 0.3693 - val_accuracy: 0.9462 - val_loss: 0.1745\n",
      "Epoch 28/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8694 - loss: 0.3625 - val_accuracy: 0.9450 - val_loss: 0.1667\n",
      "Epoch 29/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8695 - loss: 0.3548 - val_accuracy: 0.9544 - val_loss: 0.1535\n",
      "Epoch 30/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8722 - loss: 0.3458 - val_accuracy: 0.9488 - val_loss: 0.1463\n",
      "Epoch 31/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8762 - loss: 0.3410 - val_accuracy: 0.9512 - val_loss: 0.1539\n",
      "Epoch 32/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8762 - loss: 0.3362 - val_accuracy: 0.9532 - val_loss: 0.1433\n",
      "Epoch 33/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8804 - loss: 0.3288 - val_accuracy: 0.9512 - val_loss: 0.1409\n",
      "Epoch 34/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8828 - loss: 0.3203 - val_accuracy: 0.9598 - val_loss: 0.1343\n",
      "Epoch 35/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8865 - loss: 0.3102 - val_accuracy: 0.9530 - val_loss: 0.1486\n",
      "Epoch 36/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8851 - loss: 0.3203 - val_accuracy: 0.9566 - val_loss: 0.1417\n",
      "Epoch 37/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8892 - loss: 0.3024 - val_accuracy: 0.9618 - val_loss: 0.1192\n",
      "Epoch 38/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8903 - loss: 0.2962 - val_accuracy: 0.9590 - val_loss: 0.1243\n",
      "Epoch 39/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8904 - loss: 0.2997 - val_accuracy: 0.9700 - val_loss: 0.1022\n",
      "Epoch 40/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8945 - loss: 0.2882 - val_accuracy: 0.9620 - val_loss: 0.1148\n",
      "Epoch 41/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8945 - loss: 0.2919 - val_accuracy: 0.9674 - val_loss: 0.1141\n",
      "Epoch 42/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8988 - loss: 0.2782 - val_accuracy: 0.9676 - val_loss: 0.1068\n",
      "Epoch 43/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8986 - loss: 0.2770 - val_accuracy: 0.9728 - val_loss: 0.0915\n",
      "Epoch 44/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9013 - loss: 0.2715 - val_accuracy: 0.9704 - val_loss: 0.0926\n",
      "Epoch 45/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9004 - loss: 0.2749 - val_accuracy: 0.9710 - val_loss: 0.0925\n",
      "Epoch 46/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9028 - loss: 0.2680 - val_accuracy: 0.9680 - val_loss: 0.0988\n",
      "Epoch 47/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9009 - loss: 0.2694 - val_accuracy: 0.9784 - val_loss: 0.0758\n",
      "Epoch 48/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9044 - loss: 0.2611 - val_accuracy: 0.9770 - val_loss: 0.0740\n",
      "Epoch 49/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9065 - loss: 0.2558 - val_accuracy: 0.9794 - val_loss: 0.0707\n",
      "Epoch 50/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9068 - loss: 0.2554 - val_accuracy: 0.9806 - val_loss: 0.0730\n",
      "Epoch 51/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9068 - loss: 0.2546 - val_accuracy: 0.9788 - val_loss: 0.0749\n",
      "Epoch 52/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9085 - loss: 0.2528 - val_accuracy: 0.9824 - val_loss: 0.0663\n",
      "Epoch 53/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9069 - loss: 0.2507 - val_accuracy: 0.9828 - val_loss: 0.0672\n",
      "Epoch 54/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9104 - loss: 0.2421 - val_accuracy: 0.9768 - val_loss: 0.0827\n",
      "Epoch 55/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9134 - loss: 0.2361 - val_accuracy: 0.9756 - val_loss: 0.0743\n",
      "Epoch 56/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9132 - loss: 0.2418 - val_accuracy: 0.9806 - val_loss: 0.0671\n",
      "Epoch 57/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9122 - loss: 0.2463 - val_accuracy: 0.9710 - val_loss: 0.0854\n",
      "Epoch 58/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9175 - loss: 0.2294 - val_accuracy: 0.9688 - val_loss: 0.0933\n",
      "Epoch 59/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9159 - loss: 0.2278 - val_accuracy: 0.9812 - val_loss: 0.0637\n",
      "Epoch 60/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9162 - loss: 0.2333 - val_accuracy: 0.9782 - val_loss: 0.0680\n",
      "Epoch 61/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9187 - loss: 0.2258 - val_accuracy: 0.9846 - val_loss: 0.0556\n",
      "Epoch 62/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9207 - loss: 0.2196 - val_accuracy: 0.9780 - val_loss: 0.0631\n",
      "Epoch 63/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9159 - loss: 0.2298 - val_accuracy: 0.9834 - val_loss: 0.0572\n",
      "Epoch 64/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9193 - loss: 0.2236 - val_accuracy: 0.9846 - val_loss: 0.0637\n",
      "Epoch 65/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9192 - loss: 0.2235 - val_accuracy: 0.9844 - val_loss: 0.0515\n",
      "Epoch 66/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9208 - loss: 0.2192 - val_accuracy: 0.9818 - val_loss: 0.0610\n",
      "Epoch 67/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9227 - loss: 0.2123 - val_accuracy: 0.9796 - val_loss: 0.0664\n",
      "Epoch 68/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9226 - loss: 0.2131 - val_accuracy: 0.9896 - val_loss: 0.0457\n",
      "Epoch 69/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9212 - loss: 0.2157 - val_accuracy: 0.9876 - val_loss: 0.0475\n",
      "Epoch 70/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9214 - loss: 0.2173 - val_accuracy: 0.9826 - val_loss: 0.0550\n",
      "Epoch 71/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9233 - loss: 0.2115 - val_accuracy: 0.9892 - val_loss: 0.0458\n",
      "Epoch 72/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9277 - loss: 0.2000 - val_accuracy: 0.9864 - val_loss: 0.0477\n",
      "Epoch 73/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9236 - loss: 0.2153 - val_accuracy: 0.9912 - val_loss: 0.0400\n",
      "Epoch 74/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9267 - loss: 0.2030 - val_accuracy: 0.9820 - val_loss: 0.0630\n",
      "Epoch 75/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.2048 - val_accuracy: 0.9722 - val_loss: 0.0808\n",
      "Epoch 76/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9270 - loss: 0.2042 - val_accuracy: 0.9856 - val_loss: 0.0489\n",
      "Epoch 77/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9286 - loss: 0.1983 - val_accuracy: 0.9868 - val_loss: 0.0478\n",
      "Epoch 78/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9282 - loss: 0.2002 - val_accuracy: 0.9896 - val_loss: 0.0406\n",
      "Epoch 79/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.2034 - val_accuracy: 0.9894 - val_loss: 0.0385\n",
      "Epoch 80/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9300 - loss: 0.1982 - val_accuracy: 0.9890 - val_loss: 0.0399\n",
      "Epoch 81/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9322 - loss: 0.1903 - val_accuracy: 0.9870 - val_loss: 0.0412\n",
      "Epoch 82/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9319 - loss: 0.1929 - val_accuracy: 0.9894 - val_loss: 0.0396\n",
      "Epoch 83/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9288 - loss: 0.1950 - val_accuracy: 0.9850 - val_loss: 0.0493\n",
      "Epoch 84/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9306 - loss: 0.1908 - val_accuracy: 0.9880 - val_loss: 0.0390\n",
      "Epoch 85/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9287 - loss: 0.1996 - val_accuracy: 0.9928 - val_loss: 0.0333\n",
      "Epoch 86/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9328 - loss: 0.1847 - val_accuracy: 0.9900 - val_loss: 0.0366\n",
      "Epoch 87/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9327 - loss: 0.1892 - val_accuracy: 0.9848 - val_loss: 0.0472\n",
      "Epoch 88/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9334 - loss: 0.1871 - val_accuracy: 0.9884 - val_loss: 0.0392\n",
      "Epoch 89/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9332 - loss: 0.1866 - val_accuracy: 0.9832 - val_loss: 0.0522\n",
      "Epoch 90/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9352 - loss: 0.1800 - val_accuracy: 0.9900 - val_loss: 0.0351\n",
      "Epoch 91/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9336 - loss: 0.1852 - val_accuracy: 0.9918 - val_loss: 0.0302\n",
      "Epoch 92/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9348 - loss: 0.1834 - val_accuracy: 0.9912 - val_loss: 0.0320\n",
      "Epoch 93/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9344 - loss: 0.1856 - val_accuracy: 0.9906 - val_loss: 0.0367\n",
      "Epoch 94/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9361 - loss: 0.1827 - val_accuracy: 0.9890 - val_loss: 0.0394\n",
      "Epoch 95/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.1833 - val_accuracy: 0.9898 - val_loss: 0.0402\n",
      "Epoch 96/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9366 - loss: 0.1813 - val_accuracy: 0.9840 - val_loss: 0.0505\n",
      "Epoch 97/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9364 - loss: 0.1791 - val_accuracy: 0.9938 - val_loss: 0.0259\n",
      "Epoch 98/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9360 - loss: 0.1799 - val_accuracy: 0.9832 - val_loss: 0.0532\n",
      "Epoch 99/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9364 - loss: 0.1778 - val_accuracy: 0.9918 - val_loss: 0.0309\n",
      "Epoch 100/100\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9371 - loss: 0.1751 - val_accuracy: 0.9850 - val_loss: 0.0480\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7162 - loss: 1.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9220173358917236, 0.7161999940872192]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=100, batch_size=32, validation_data=(X_vali, y_vali))\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7811e8f",
   "metadata": {},
   "source": [
    "__9__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1601da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Input\n",
    "\n",
    "def build_lenet5_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # C1: Convolutional Layer (6 filters, 5x5)\n",
    "    x = Conv2D(filters=6, kernel_size=(5, 5), activation='tanh', padding='same')(inputs)\n",
    "\n",
    "    # S2: Average Pooling Layer (2x2)\n",
    "    x = AveragePooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "\n",
    "    # C3: Convolutional Layer (16 filters, 5x5)\n",
    "    x = Conv2D(filters=16, kernel_size=(5, 5), activation='tanh', padding='same')(x)\n",
    "\n",
    "    # S4: Average Pooling Layer (2x2)\n",
    "    x = AveragePooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "\n",
    "    # C5: Convolutional Layer (120 filters, 5x5)\n",
    "    x = Conv2D(filters=120, kernel_size=(5, 5), activation='tanh', padding='same')(x)\n",
    "\n",
    "    # Flatten before fully connected layers\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # F6: Fully Connected Layer with 84 units\n",
    "    x = Dense(units=84, activation='tanh')(x)\n",
    "\n",
    "    # Output Layer\n",
    "    outputs = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f94b8",
   "metadata": {},
   "source": [
    "__10__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff68e176",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_and_preprocess_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Predict text from a new image\u001b[39;00m\n\u001b[32m      5\u001b[39m new_image_path = \u001b[33m'\u001b[39m\u001b[33m./dataset/train/cat/1794.png\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m new_image = \u001b[43mload_and_preprocess_image\u001b[49m(new_image_path)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      9\u001b[39m     prediction = model.predict(np.expand_dims(new_image, axis=\u001b[32m0\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'load_and_preprocess_image' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Predict text from a new image\n",
    "new_image_path = './dataset/train/cat/1794.png'\n",
    "new_image = load_and_preprocess_image(new_image_path)\n",
    "\n",
    "if new_image is not None:\n",
    "    prediction = model.predict(np.expand_dims(new_image, axis=0))\n",
    "    predicted_label = np.argmax(prediction)\n",
    "\n",
    "    # Get the Bengali character using the mapping dictionary\n",
    "    predicted_text = animal_img_map.get(predicted_label, \"Unknown\")\n",
    "\n",
    "    print(f\"Predicted label: {predicted_label}, Predicted text: {predicted_text}\")\n",
    "\n",
    "    # Display the image using OpenCV\n",
    "    img = cv2.imread(new_image_path)\n",
    "    # cv2.imshow(img)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Unable to read the new image.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
